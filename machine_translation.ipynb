{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SOBIKA-G/Machine-Translation/blob/main/machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IXisvfQozEf",
        "outputId": "0226048b-b40a-432d-e91a-96f30fac1f83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   English                  French\n",
            "0  English words/sentences  French words/sentences\n",
            "1                      Hi.                  Salut!\n",
            "2                     Run!                 Cours !\n",
            "3                     Run!                Courez !\n",
            "4                     Who?                   Qui ?\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "\n",
        "# Load the dataset (replace 'your_dataset.csv' with the actual dataset path)\n",
        "data = pd.read_csv('/content/drive/MyDrive/eng_-french.csv', header=None, names=['English', 'French'])\n",
        "\n",
        "# Extract English and French sentences from the dataset (first 1000 rows)\n",
        "english_sentences = data['English'][:5000]\n",
        "french_sentences = data['French'][:5000]\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "_4lMo1oWo3zR",
        "outputId": "1817233d-0152-4572-de41-5da5c2f949fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "English    0\n",
              "French     0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>English</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>French</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "IXuDWdB8o6qX",
        "outputId": "51849b60-02b1-4b76-870d-850186d8984f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  English  \\\n",
              "count                                              175622   \n",
              "unique                                             123101   \n",
              "top     I can't tell you how happy I am that you've co...   \n",
              "freq                                                   32   \n",
              "\n",
              "                           French  \n",
              "count                      175622  \n",
              "unique                     165976  \n",
              "top     Comment cela se peut-il ?  \n",
              "freq                            9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7378893b-b39a-4c6d-a275-1678565b240b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>175622</td>\n",
              "      <td>175622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>123101</td>\n",
              "      <td>165976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>I can't tell you how happy I am that you've co...</td>\n",
              "      <td>Comment cela se peut-il ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>32</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7378893b-b39a-4c6d-a275-1678565b240b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7378893b-b39a-4c6d-a275-1678565b240b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7378893b-b39a-4c6d-a275-1678565b240b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e49e9eab-76f7-4df1-906b-54ad13f5d227\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e49e9eab-76f7-4df1-906b-54ad13f5d227')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e49e9eab-76f7-4df1-906b-54ad13f5d227 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          123101,\n          \"32\",\n          \"175622\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"French\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          165976,\n          \"9\",\n          \"175622\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHm-atWhpC1f",
        "outputId": "eee6d75b-2489-48ff-a154-aa2dabd0b1e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(175622, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z30H_pphgHO4",
        "outputId": "de24e2a7-5b36-4696-b5bd-d98688612250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 251ms/step - accuracy: 0.7612 - loss: 2.1419\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 250ms/step - accuracy: 0.7987 - loss: 1.3004\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 255ms/step - accuracy: 0.8234 - loss: 1.0400\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 245ms/step - accuracy: 0.8421 - loss: 0.8241\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 248ms/step - accuracy: 0.8641 - loss: 0.6291\n",
            "Test Accuracy: 0.9163\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the data\n",
        "source_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "target_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# Fit the tokenizers on the data\n",
        "source_tokenizer.fit_on_texts(english_sentences)\n",
        "target_tokenizer.fit_on_texts(french_sentences)\n",
        "\n",
        "# Convert sentences to sequences\n",
        "source_sequences = source_tokenizer.texts_to_sequences(english_sentences)\n",
        "target_sequences = target_tokenizer.texts_to_sequences(french_sentences)\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "max_source_length = max(len(seq) for seq in source_sequences)\n",
        "max_target_length = max(len(seq) for seq in target_sequences)\n",
        "\n",
        "source_padded = pad_sequences(source_sequences, maxlen=max_source_length, padding='post')\n",
        "target_padded = pad_sequences(target_sequences, maxlen=max_target_length, padding='post')\n",
        "\n",
        "# Define the model architecture (Seq2Seq with LSTM)\n",
        "embedding_dim = 256\n",
        "latent_dim = 512\n",
        "vocab_size_source = len(source_tokenizer.word_index) + 1\n",
        "vocab_size_target = len(target_tokenizer.word_index) + 1\n",
        "\n",
        "# Encoder\n",
        "encoder_input = Input(shape=(max_source_length,))\n",
        "encoder_embedding = Embedding(vocab_size_source, embedding_dim)(encoder_input)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_input = Input(shape=(max_target_length-1,))  # Adjust target length for input to decoder\n",
        "decoder_embedding = Embedding(vocab_size_target, embedding_dim)(decoder_input)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size_target, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_input, decoder_input], decoder_outputs)\n",
        "\n",
        "# Compile the model with SparseCategoricalCrossentropy\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare shifted target sequences for training\n",
        "target_padded_shifted = target_padded[:, :-1]\n",
        "target_padded_labels = target_padded[:, 1:]\n",
        "\n",
        "# Train the model\n",
        "model.fit([source_padded, target_padded_shifted], np.expand_dims(target_padded_labels, -1), batch_size=8, epochs=5)\n",
        "\n",
        "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "\n",
        "source_test_padded = source_padded[:1000]\n",
        "target_test_padded_shifted = target_padded[:1000, :-1]\n",
        "target_test_labels = target_padded[:1000, 1:]\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        \"source\": source_test_padded,\n",
        "        \"target\": target_test_padded_shifted,\n",
        "    },\n",
        "    np.expand_dims(target_test_labels, -1)\n",
        ")).batch(8)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "for inputs, labels in test_dataset:\n",
        "    # Make predictions\n",
        "    predictions = model([inputs[\"source\"], inputs[\"target\"]], training=False)\n",
        "\n",
        "    # Update the accuracy metric\n",
        "    accuracy_metric.update_state(labels, predictions)\n",
        "\n",
        "# Get the accuracy result\n",
        "accuracy = accuracy_metric.result().numpy()\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "yEjq8JFSAzqR",
        "outputId": "359cdebc-4654-4cc4-8bed-66ef5e74781a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_45\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_45\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_39            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_40            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_38 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m319,488\u001b[0m │ input_layer_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_39 (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m697,344\u001b[0m │ input_layer_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_38 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_39 (\u001b[38;5;33mLSTM\u001b[0m)            │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m),       │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],         │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ lstm_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m2724\u001b[0m)        │      \u001b[38;5;34m1,397,412\u001b[0m │ lstm_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_39            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_40            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">319,488</span> │ input_layer_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">697,344</span> │ input_layer_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)            │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],         │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ lstm_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2724</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,397,412</span> │ lstm_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,692,206\u001b[0m (63.68 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,692,206</span> (63.68 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,564,068\u001b[0m (21.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,564,068</span> (21.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m11,128,138\u001b[0m (42.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,128,138</span> (42.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vP09ibtsQdX",
        "outputId": "688bb7bd-d27e-4769-f6df-66058c38fd49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('translation_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the source tokenizer\n",
        "with open(\"source_tokenizer.pkl\", \"wb\") as source_file:\n",
        "    pickle.dump(source_tokenizer, source_file)\n",
        "\n",
        "# Save the target tokenizer\n",
        "with open(\"target_tokenizer.pkl\", \"wb\") as target_file:\n",
        "    pickle.dump(target_tokenizer, target_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "sHMqGiNKziLA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6GwQgB0BOig",
        "outputId": "737a5978-2e30-4fa4-af79-42725f9cd21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an English sentence: hello\n",
            "Translated Sentence: fume\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# Load the model and tokenizers\n",
        "def load_model_and_tokenizers():\n",
        "    # Load the trained model\n",
        "    model = tf.keras.models.load_model(\"/content/drive/MyDrive/translation_model.h5\")\n",
        "\n",
        "    # Load the tokenizers\n",
        "    with open(\"/content/source_tokenizer.pkl\", \"rb\") as source_file:\n",
        "        source_tokenizer = pickle.load(source_file)\n",
        "\n",
        "    with open(\"/content/target_tokenizer.pkl\", \"rb\") as target_file:\n",
        "        target_tokenizer = pickle.load(target_file)\n",
        "\n",
        "    return model, source_tokenizer, target_tokenizer\n",
        "\n",
        "# Load the model and tokenizers globally\n",
        "model, source_tokenizer, target_tokenizer = load_model_and_tokenizers()\n",
        "\n",
        "# Define max lengths (adjust according to model's expected length)\n",
        "max_source_length = 4  # Adjusted to match the model's expected input length\n",
        "max_target_length = 10  # Adjust as per your training setup\n",
        "\n",
        "# Translation function\n",
        "def translate_sentence(input_sentence):\n",
        "    # Tokenize and pad the input sentence to max_length = 4 (as per model requirement)\n",
        "    input_sequence = source_tokenizer.texts_to_sequences([input_sentence])\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=max_source_length, padding='post')\n",
        "\n",
        "    # Initialize target sequence for decoding (with the <start> token)\n",
        "    target_sequence = np.zeros((1, max_target_length - 1))  # excluding the <start> token\n",
        "    start_token = target_tokenizer.word_index.get('<start>', 1)\n",
        "    end_token = target_tokenizer.word_index.get('<end>', 0)\n",
        "\n",
        "    target_sequence[0, 0] = start_token\n",
        "\n",
        "    # Prepare to generate translation\n",
        "    predicted_sequence = []\n",
        "    for i in range(1, max_target_length):\n",
        "        # The model expects both the source and target input sequences\n",
        "        output = model.predict([input_padded, target_sequence], verbose=0)\n",
        "        predicted_id = np.argmax(output[0, i - 1, :])\n",
        "\n",
        "        # Stop if the <end> token is predicted\n",
        "        if predicted_id == end_token:\n",
        "            break\n",
        "\n",
        "        predicted_sequence.append(predicted_id)\n",
        "        target_sequence[0, i] = predicted_id\n",
        "\n",
        "    # Convert predicted token IDs to words\n",
        "    translated_sentence = ' '.join(target_tokenizer.index_word.get(id, '') for id in predicted_sequence if id > 0)\n",
        "    return translated_sentence\n",
        "\n",
        "# Get input from the user\n",
        "input_sentence = input(\"Enter an English sentence: \")\n",
        "\n",
        "# Translate and print the output\n",
        "translated_sentence = translate_sentence(input_sentence)\n",
        "print(f\"Translated Sentence: {translated_sentence}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def compute_bleu(reference, predicted):\n",
        "    reference_tokens = nltk.word_tokenize(reference)\n",
        "    predicted_tokens = nltk.word_tokenize(predicted)\n",
        "\n",
        "    if len(predicted_tokens) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return sentence_bleu([reference_tokens], predicted_tokens)\n",
        "\n",
        "\n",
        "def evaluate_bleu(input_sentences, target_sentences, model, source_tokenizer, target_tokenizer, max_source_length, max_target_length):\n",
        "\n",
        "    def translate_sentence(input_sentence, model, source_tokenizer, target_tokenizer, max_source_length, max_target_length):\n",
        "        input_sequence = source_tokenizer.texts_to_sequences([input_sentence])\n",
        "        input_padded = pad_sequences(input_sequence, maxlen=max_source_length, padding='post')\n",
        "\n",
        "        target_sequence = np.zeros((1, max_target_length - 1))\n",
        "        start_token = target_tokenizer.word_index.get('<start>', 1)\n",
        "        end_token = target_tokenizer.word_index.get('<end>', 0)\n",
        "\n",
        "        target_sequence[0, 0] = start_token\n",
        "\n",
        "        predicted_sequence = []\n",
        "        for i in range(1, max_target_length):\n",
        "            output = model.predict([input_padded, target_sequence], verbose=0)\n",
        "            predicted_id = np.argmax(output[0, i - 1, :])\n",
        "\n",
        "            if predicted_id == end_token:\n",
        "                break\n",
        "\n",
        "            predicted_sequence.append(predicted_id)\n",
        "            target_sequence[0, i] = predicted_id\n",
        "\n",
        "        translated_sentence = ' '.join(target_tokenizer.index_word.get(id, '') for id in predicted_sequence if id > 0)\n",
        "        return translated_sentence\n",
        "\n",
        "    total_bleu_score = 0.0\n",
        "    for i in range(len(input_sentences)):\n",
        "        input_sentence = input_sentences[i]\n",
        "        reference_translation = target_sentences[i]\n",
        "\n",
        "        predicted_translation = translate_sentence(input_sentence, model, source_tokenizer, target_tokenizer, max_source_length, max_target_length)\n",
        "\n",
        "        bleu_score = compute_bleu(reference_translation, predicted_translation)\n",
        "        total_bleu_score += bleu_score\n",
        "\n",
        "        print(f\"Input: {input_sentence}\")\n",
        "        print(f\"Reference: {reference_translation}\")\n",
        "        print(f\"Translated: {predicted_translation}\")\n",
        "        print(f\"BLEU: {bleu_score}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    average_bleu_score = total_bleu_score / len(input_sentences)\n",
        "    return average_bleu_score\n",
        "\n",
        "\n",
        "# Example usage (in your new cell):\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/translation_model.h5\"  # Replace with your actual path\n",
        "source_tokenizer_path = \"/content/source_tokenizer.pkl\"  # Replace with your actual path\n",
        "target_tokenizer_path = \"/content/target_tokenizer.pkl\"  # Replace with your actual path\n",
        "test_data_path = '/content/drive/MyDrive/eng_-french.csv' # Replace with your actual path\n",
        "\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "with open(source_tokenizer_path, \"rb\") as source_file:\n",
        "    source_tokenizer = pickle.load(source_file)\n",
        "with open(target_tokenizer_path, \"rb\") as target_file:\n",
        "    target_tokenizer = pickle.load(target_file)\n",
        "\n",
        "max_source_length = 4  # Replace with your actual value\n",
        "max_target_length = 10  # Replace with your actual value\n",
        "\n",
        "test_data = pd.read_csv(test_data_path, header=None, names=['English', 'French'])\n",
        "\n",
        "test_data_sliced = test_data.iloc[5000:5100] # or whatever your test range is\n",
        "test_data_sliced = test_data_sliced.reset_index(drop=True) # Important: Reset the index!\n",
        "\n",
        "test_english_sentences = test_data_sliced['English']\n",
        "test_french_sentences = test_data_sliced['French']\n",
        "\n",
        "average_bleu = evaluate_bleu(test_english_sentences, test_french_sentences, model, source_tokenizer, target_tokenizer, max_source_length, max_target_length)\n",
        "print(f\"Average BLEU Score on Test Data: {average_bleu}\")"
      ],
      "metadata": {
        "id": "uiMuoJMy-YM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2395b4fd-6367-41a8-a5c8-d14debbf7462"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d246df840e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Don't deny it.\n",
            "Reference: Ne le nie pas !\n",
            "Translated: le lirai\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: Don't deny it.\n",
            "Reference: Ne le niez pas !\n",
            "Translated: le lirai\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: Don't despair.\n",
            "Reference: Ne désespérez pas !\n",
            "Translated: te prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't despair.\n",
            "Reference: Ne désespère pas !\n",
            "Translated: te prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't do that.\n",
            "Reference: Ne fais pas cela.\n",
            "Translated: le déteste\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't do that.\n",
            "Reference: Ne fais pas ça.\n",
            "Translated: le déteste\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't do that.\n",
            "Reference: Ne faites pas ça.\n",
            "Translated: le déteste\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't do this.\n",
            "Reference: Ne fais pas ça !\n",
            "Translated: le déteste\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't do this.\n",
            "Reference: Ne faites pas ça !\n",
            "Translated: le déteste\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't get fat.\n",
            "Reference: Ne deviens pas gras.\n",
            "Translated: ne sors pas avec un ski\n",
            "BLEU: 1.1640469867513693e-231\n",
            "--------------------\n",
            "Input: Don't get fat.\n",
            "Reference: Ne grossis pas.\n",
            "Translated: ne sors pas avec un ski\n",
            "BLEU: 1.1640469867513693e-231\n",
            "--------------------\n",
            "Input: Don't give up!\n",
            "Reference: N'abandonne pas !\n",
            "Translated: te paierai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't give up.\n",
            "Reference: N'abandonne pas.\n",
            "Translated: te paierai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't give up.\n",
            "Reference: N'abandonnez pas.\n",
            "Translated: te paierai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't give up.\n",
            "Reference: Ne laisse pas tomber.\n",
            "Translated: te paierai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't give up.\n",
            "Reference: Ne laissez pas tomber.\n",
            "Translated: te paierai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't hang up!\n",
            "Reference: Ne raccroche pas !\n",
            "Translated: serai pas\n",
            "BLEU: 5.635809992474887e-232\n",
            "--------------------\n",
            "Input: Don't hang up!\n",
            "Reference: Ne raccrochez pas !\n",
            "Translated: serai pas\n",
            "BLEU: 5.635809992474887e-232\n",
            "--------------------\n",
            "Input: Don't hurt me.\n",
            "Reference: Ne me fais pas de mal !\n",
            "Translated: me suis senti deux\n",
            "BLEU: 6.085166479973199e-232\n",
            "--------------------\n",
            "Input: Don't kill me.\n",
            "Reference: Ne me tue pas !\n",
            "Translated: t'ai eu\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't kill me.\n",
            "Reference: Ne me tuez pas !\n",
            "Translated: t'ai eu\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Don't mock me.\n",
            "Reference: Ne te moque pas de moi.\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 9.711929667259895e-232\n",
            "--------------------\n",
            "Input: Don't push it.\n",
            "Reference: Ne pousse pas le bouchon !\n",
            "Translated: le lirai\n",
            "BLEU: 2.0732986305800918e-232\n",
            "--------------------\n",
            "Input: Don't push it.\n",
            "Reference: Ne le pousse pas !\n",
            "Translated: le lirai\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: Don't push it.\n",
            "Reference: Ne poussez pas le bouchon !\n",
            "Translated: le lirai\n",
            "BLEU: 2.0732986305800918e-232\n",
            "--------------------\n",
            "Input: Don't push it.\n",
            "Reference: Pousse pas le bouchon !\n",
            "Translated: le lirai\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: Don't push it.\n",
            "Reference: Poussez pas le bouchon !\n",
            "Translated: le lirai\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: Don't push me!\n",
            "Reference: Ne me pousse pas !\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 1.2183324802375697e-231\n",
            "--------------------\n",
            "Input: Don't push me!\n",
            "Reference: Ne me poussez pas !\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 1.2183324802375697e-231\n",
            "--------------------\n",
            "Input: Don't push me.\n",
            "Reference: Ne me pousse pas !\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 1.2183324802375697e-231\n",
            "--------------------\n",
            "Input: Don't push me.\n",
            "Reference: Ne me poussez pas !\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 1.2183324802375697e-231\n",
            "--------------------\n",
            "Input: Don't sass me.\n",
            "Reference: Ne sois pas impertinent à mon égard.\n",
            "Translated: ne suis pas à moi\n",
            "BLEU: 7.951455490316087e-232\n",
            "--------------------\n",
            "Input: Don't tell me.\n",
            "Reference: Ne me le dis pas.\n",
            "Translated: me suis pas en sécurité\n",
            "BLEU: 1.1862177682648818e-231\n",
            "--------------------\n",
            "Input: Don't tell me.\n",
            "Reference: M'en parle pas.\n",
            "Translated: me suis pas en sécurité\n",
            "BLEU: 1.2183324802375697e-231\n",
            "--------------------\n",
            "Input: Don't wait up.\n",
            "Reference: Ne veille pas.\n",
            "Translated: te fais pas\n",
            "BLEU: 9.918892480173173e-232\n",
            "--------------------\n",
            "Input: Don't wait up.\n",
            "Reference: Ne veillez pas.\n",
            "Translated: te fais pas\n",
            "BLEU: 9.918892480173173e-232\n",
            "--------------------\n",
            "Input: Draw a circle.\n",
            "Reference: Trace un cercle.\n",
            "Translated: suis alité\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Draw a circle.\n",
            "Reference: Trace un cercle !\n",
            "Translated: suis alité\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Draw a circle.\n",
            "Reference: Tracez un cercle !\n",
            "Translated: suis alité\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Drink it down.\n",
            "Reference: Bois-le !\n",
            "Translated: le mérite\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Drink it down.\n",
            "Reference: Buvez-le !\n",
            "Translated: le mérite\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Drop your gun!\n",
            "Reference: Laisse tomber ton arme !\n",
            "Translated: n'ai aucune idée\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Drop your gun!\n",
            "Reference: Laissez tomber votre arme !\n",
            "Translated: n'ai aucune idée\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Dry your eyes.\n",
            "Reference: Sèche tes larmes.\n",
            "Translated: vous prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Dry your eyes.\n",
            "Reference: Essuie tes yeux.\n",
            "Translated: vous prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat and drink.\n",
            "Reference: Mangez et buvez.\n",
            "Translated: mange\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat and drink.\n",
            "Reference: Mange et bois.\n",
            "Translated: mange\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat something.\n",
            "Reference: Mange quelque chose !\n",
            "Translated: parlerai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat something.\n",
            "Reference: Mangez quelque chose !\n",
            "Translated: parlerai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat your peas.\n",
            "Reference: Mange tes petits pois.\n",
            "Translated: parlerai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Eat your peas.\n",
            "Reference: Mangez vos petits pois.\n",
            "Translated: parlerai\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Even Tom lied.\n",
            "Reference: Même Tom a menti.\n",
            "Translated: lui demande là\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Everyone dies.\n",
            "Reference: Tout le monde meurt.\n",
            "Translated: toi\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Everyone sang.\n",
            "Reference: Tout le monde chanta.\n",
            "Translated: toi\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Everyone wins.\n",
            "Reference: Tout le monde y gagne.\n",
            "Translated: toi\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Feed the bird!\n",
            "Reference: Nourris l'oiseau !\n",
            "Translated: le ici\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Feed the bird.\n",
            "Reference: Nourris l'oiseau !\n",
            "Translated: le ici\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Feed the bird.\n",
            "Reference: Nourrissez l'oiseau.\n",
            "Translated: le ici\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get a haircut.\n",
            "Reference: Va te faire couper les cheveux !\n",
            "Translated: suis au lit\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get back here.\n",
            "Reference: Reviens ici !\n",
            "Translated: toi ici\n",
            "BLEU: 9.291879812217675e-232\n",
            "--------------------\n",
            "Input: Get back here.\n",
            "Reference: Revenez ici !\n",
            "Translated: toi ici\n",
            "BLEU: 9.291879812217675e-232\n",
            "--------------------\n",
            "Input: Get off of me.\n",
            "Reference: Lâche-moi.\n",
            "Translated: me essaie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get some rest.\n",
            "Reference: Prenez quelque repos !\n",
            "Translated: me suis prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your coat.\n",
            "Reference: Prends ton manteau.\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Va chercher ton matériel !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Allez chercher votre matériel !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Va chercher ta tenue !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Allez chercher votre tenue !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Va chercher tes affaires !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Get your gear.\n",
            "Reference: Allez chercher vos affaires !\n",
            "Translated: vous prêt\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give him time.\n",
            "Reference: Donne-lui du temps.\n",
            "Translated: le suppose\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give it to me!\n",
            "Reference: Donne-le-moi !\n",
            "Translated: vais au travail\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give it to me.\n",
            "Reference: Donnez-le-moi.\n",
            "Translated: vais au travail\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give it to me.\n",
            "Reference: Donne-le-moi.\n",
            "Translated: vais au travail\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give it to me.\n",
            "Reference: Donne-la-moi.\n",
            "Translated: vais au travail\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give it to me.\n",
            "Reference: Donnez-la-moi.\n",
            "Translated: vais au travail\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give me a few.\n",
            "Reference: Donne-m'en quelques-uns.\n",
            "Translated: me suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give me a hug.\n",
            "Reference: Serre-moi dans tes bras !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give me a hug.\n",
            "Reference: Serrez-moi dans vos bras !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give me a sec.\n",
            "Reference: Donne-moi une seconde.\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Give me a sec.\n",
            "Reference: Donnez-moi une seconde.\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: God bless you!\n",
            "Reference: Que Dieu te bénisse !\n",
            "Translated: vous prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: God bless you!\n",
            "Reference: Dieu vous bénisse !\n",
            "Translated: vous prie\n",
            "BLEU: 5.635809992474887e-232\n",
            "--------------------\n",
            "Input: God bless you!\n",
            "Reference: Dieu te bénisse !\n",
            "Translated: vous prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: God bless you!\n",
            "Reference: Que Dieu vous bénisse !\n",
            "Translated: vous prie\n",
            "BLEU: 3.418291552750845e-232\n",
            "--------------------\n",
            "Input: God knows why.\n",
            "Reference: Dieu sait pourquoi.\n",
            "Translated: me prie\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Guess who won.\n",
            "Reference: Devine qui a gagné.\n",
            "Translated: le connais\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Guess who won.\n",
            "Reference: Devinez qui a gagné.\n",
            "Translated: le connais\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Hand it to me.\n",
            "Reference: Passe-le-moi.\n",
            "Translated: vois bien\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Hang on tight!\n",
            "Reference: Accroche-toi bien !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Hang on tight!\n",
            "Reference: Accrochez-vous bien !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Hang on tight.\n",
            "Reference: Accroche-toi bien !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Hang on tight.\n",
            "Reference: Accrochez-vous bien !\n",
            "Translated: suis un menteur\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Have a cookie.\n",
            "Reference: Prends un biscuit !\n",
            "Translated: suis un homme\n",
            "BLEU: 9.918892480173173e-232\n",
            "--------------------\n",
            "Input: Have him come.\n",
            "Reference: Fais-le venir.\n",
            "Translated: le veux\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Have some ham.\n",
            "Reference: Prends du jambon.\n",
            "Translated: dispose à la maison\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: Have some ham.\n",
            "Reference: Prenez du jambon.\n",
            "Translated: dispose à la maison\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: He broke them.\n",
            "Reference: Il les a cassés.\n",
            "Translated: le ai vues\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: He broke them.\n",
            "Reference: Il les a cassées.\n",
            "Translated: le ai vues\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Input: He can't sing.\n",
            "Reference: Il est incapable de chanter.\n",
            "Translated: ne puis pas à voir\n",
            "BLEU: 0\n",
            "--------------------\n",
            "Average BLEU Score on Test Data: 2.097125066871487e-232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gP6tNJpNRpOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rk-zYIQomH2IhXNrB8eer0ul7NId2aME",
      "authorship_tag": "ABX9TyMEyFn94WaWtpjUWbWcSK3I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}